<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <link rel="icon" href="favicon.ico">
    <title>Homepage of Jingkuan Song, UESTC</title>
    <script defer="" src="js/chunk-vendors.js"></script>
    <script defer="" src="js/app.js"></script>
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            font-family: "OpenSans", Helvetica, Arial, sans-serif;
            font-weight: 400;
            font-size: 15px;
            color: #555;
            line-height: 22px;
        }
    </style>
    <style type="text/css">
        .sc-item[data-v-0ff541a6] {
            margin-bottom: 10px;
        }
    </style>
    <style type="text/css">
        .sl-container[data-v-5cd10541] {
            box-shadow: 0 6px 5px -7px gray;
            padding: 30px 1%;
            color: #555;
        }
    </style>
    <style type="text/css">
        .lc-container[data-v-62a49cd2] {
            box-shadow: 0 6px 5px -7px gray;
        }

        .lc-box[data-v-62a49cd2] {
            padding: 10px 0 20px 0;
            border-bottom: solid 1px #EEE;
            display: flex;
        }

        .lc-cover[data-v-62a49cd2] {
            width: 150px;
            height: auto;
            margin-right: 50px;
        }

        .lc-title[data-v-62a49cd2] {
            font-weight: bold;
        }

        .lc-info[data-v-62a49cd2] {
            margin: 10px 0 10px 0;
            font-style: italic;
        }

        .lc-publish[data-v-62a49cd2] {
            color: #500;
            margin-right: 20px;
        }

        .lc-link-box[data-v-62a49cd2] {
            display: flex;
        }

        .lc-link[data-v-62a49cd2] {
            color: #0088CC;
            margin: 0 2px 0 5px;
        }

        img[data-v-62a49cd2] {
            width: 100%;
            height: auto;
            border-radius: 5px;
        }

        h2[data-v-62a49cd2] {
            font-size: 30px;
            color: #970024;
        }
    </style>
    <style type="text/css">
        .l-link[data-v-702382f0] {
            color: #0088CC;
        }

        .sep[data-v-702382f0] {
            margin: 0 2px 0 0;
        }

        p[data-v-702382f0] {
            float: left;
            word-break: break-all;
            margin: 0 0 10px;
        }
    </style>
    <style type="text/css">
        .container[data-v-0c6f0290] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }

        .info-box[data-v-0c6f0290] {
            width: 100%;
            display: flex;
            box-shadow: 0 6px 5px -7px gray;
            padding: 10px 1%;
        }

        .avatar-box[data-v-0c6f0290] {
            width: 35%;
            height: auto;
            margin-top: 15px;
            padding: 0 1.5%;
        }

        .info[data-v-0c6f0290] {
            width: 60%;
            padding: 0 1.5%;
        }

        .pad[data-v-0c6f0290] {
            width: 5%;
        }

        .job-title[data-v-0c6f0290] {
            font-style: italic;
            margin: 0 0 10px;
        }

        img[data-v-0c6f0290] {
            width: 100%;
            height: auto;
            border-radius: 5px;
        }

        h1[data-v-0c6f0290] {
            font-size: 36px;
            color: darkblue;
            margin: 0 0 10px;
        }
    </style>
    <style type="text/css">
        li[data-v-1eaa13bc] {
            padding-left: 20px;
        }
    </style>
    <style type="text/css">
        h1[data-v-3a4951d4] {
            font-size: 30px;
            color: darkblue;
            padding-bottom: 10px;
            border-bottom: solid 1px #EEE;
        }
    </style>
    <style type="text/css">
        .container[data-v-0a2d6c68] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        .container[data-v-dcb24c48] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        .container[data-v-247c96ae] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        .container[data-v-606756d4] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        ._th-container ._th-item {
            margin-bottom: 3px;
            position: relative;
            width: 0;
            height: 0;
            cursor: pointer;
            opacity: .3;
            background-color: aquamarine;
            border-radius: 100%;
            text-align: center;
            line-height: 30px;
            -webkit-transition: all .35s;
            -o-transition: all .35s;
            transition: all .35s;
            right: 30px
        }

        ._th-container ._th-item,
        ._th-container ._th-click-hover,
        ._th_cover-all-show-times ._th_times {
            -webkit-box-shadow: -3px 4px 12px -5px black;
            box-shadow: -3px 4px 12px -5px black
        }

        ._th-container:hover ._th-item._item-x2 {
            margin-left: 18px;
            width: 40px;
            height: 40px;
            line-height: 40px
        }

        ._th-container:hover ._th-item._item-x-2 {
            margin-left: 17px;
            width: 38px;
            height: 38px;
            line-height: 38px
        }

        ._th-container:hover ._th-item._item-xx2 {
            width: 36px;
            height: 36px;
            margin-left: 16px;
            line-height: 36px
        }

        ._th-container:hover ._th-item._item-xx-2 {
            width: 32px;
            height: 32px;
            line-height: 32px;
            margin-left: 14px
        }

        ._th-container:hover ._th-item._item-reset {
            width: 30px;
            line-height: 30px;
            height: 30px;
            margin-left: 10px
        }

        ._th-click-hover {
            position: relative;
            -webkit-transition: all .5s;
            -o-transition: all .5s;
            transition: all .5s;
            height: 45px;
            width: 45px;
            cursor: pointer;
            opacity: .3;
            border-radius: 100%;
            background-color: aquamarine;
            text-align: center;
            line-height: 45px;
            right: 0
        }

        ._th-container:hover {
            left: -5px
        }

        ._th-container {
            font-size: 12px;
            -webkit-transition: all .5s;
            -o-transition: all .5s;
            transition: all .5s;
            left: -35px;
            top: 20%;
            position: fixed;
            -webkit-box-sizing: border-box;
            box-sizing: border-box;
            z-index: 100000;
            -webkit-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            user-select: none
        }

        ._th-container ._th-item:hover {
            opacity: .8;
            background-color: #5fb492;
            color: aliceblue
        }

        ._th-container ._th-item:active {
            opacity: .9;
            background-color: #1b3a26;
            color: aliceblue
        }

        ._th-container:hover ._th-click-hover {
            opacity: .8
        }

        ._th-container:hover ._th-item {
            opacity: .6;
            right: 0
        }

        ._th-container ._th-click-hover:hover {
            opacity: .8;
            background-color: #5fb492;
            color: aliceblue
        }

        ._th_cover-all-show-times {
            position: fixed;
            top: 0;
            right: 0;
            width: 100%;
            height: 100%;
            z-index: 99999;
            opacity: 1;
            font-weight: 900;
            font-size: 30px;
            color: #4f4f4f;
            background-color: rgba(0, 0, 0, 0.1)
        }

        ._th_cover-all-show-times._th_hidden {
            z-index: -99999;
            opacity: 0;
            -webkit-transition: 1s all;
            -o-transition: 1s all;
            transition: 1s all
        }

        ._th_cover-all-show-times ._th_times {
            width: 300px;
            height: 300px;
            border-radius: 50%;
            background-color: rgba(127, 255, 212, 0.51);
            text-align: center;
            line-height: 300px;
            position: absolute;
            top: 50%;
            right: 50%;
            margin-top: -150px;
            margin-right: -150px
        }
    </style>
</head>

<body>
    <noscript>
        <strong>We're sorry but songjingkuan doesn't work properly without JavaScript enabled. Please enable it to
            continue.</strong>
    </noscript>
    <div id="app" data-v-app="">
        <div id="container">
            <div class="container" data-v-dcb24c48="">
                <p data-v-702382f0=""><span class="l-box" data-v-702382f0=""><a href="index.html" class="l-link"
                            data-v-702382f0="">Back</a><span class="sep" data-v-702382f0=""> | </span></span><span
                        class="l-box" data-v-702382f0=""><a href="compact-representation.html" class="l-link"
                            data-v-702382f0="">Compact Representation</a><span class="sep" data-v-702382f0=""> |
                        </span></span><span class="l-box" data-v-702382f0=""><a href="cross-media-analysis.html"
                            class="l-link" data-v-702382f0="">Cross-media Analysis</a><span class="sep"
                            data-v-702382f0=""> | </span></span><span class="l-box" data-v-702382f0=""><a
                            href="ai-safety.html" class="l-link" data-v-702382f0="">Representation Safety</a>
                        <!--v-if-->
                    </span></p>
                <div data-v-702382f0="" style="clear: both;"></div>
                <div class="lc-container" data-v-62a49cd2="" data-v-dcb24c48="">
                    <h2 data-v-62a49cd2="">Compact Representation</h2>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport12.07fac307.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">24. Unified Multivariate Gaussian Mixture for
                                    Efficient Neural Image Compression</div>
                                <div class="lc-info" data-v-62a49cd2="">Xiaosu Zhu, Jingkuan Song, Lianli Gao, Feng
                                    Zheng, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">CVPR 2022</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/2203.10897.pdf" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href="https://github.com/xiaosu-zhu/McQuic"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport21.e3dad006.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">23. Meta Distribution Alignment for
                                    Generalizable Person Re-Identification</div>
                                <div class="lc-info" data-v-62a49cd2="">Hao Ni, Jingkuan Song, Xiaopeng Luo, Feng Zheng,
                                    Wen Li, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">CVPR 2022</div><a class="lc-link"
                                        href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ni_Meta_Distribution_Alignment_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.pdf"
                                        data-v-62a49cd2="">PDF</a><a class="lc-link"
                                        href="https://github.com/haoni0812/MDA.git" data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport23.e8aacd88.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">22. Continual Referring Expression
                                    Comprehension via Dual Modular Memorization</div>
                                <div class="lc-info" data-v-62a49cd2="">Heng Tao Shen, Cheng Chen, Peng Wang, Lianli
                                    Gao, Meng Wang, Jingkuan Song</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Image Process. 2022</div><a
                                        class="lc-link"
                                        href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9916159"
                                        data-v-62a49cd2="">PDF</a><a class="lc-link"
                                        href="https://github.com/zackschen/DMM" data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport9.1f5d6816.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">21. Learning Efficient Hash Codes for Fast
                                    Graph-Based Data Similarity Retrieval</div>
                                <div class="lc-info" data-v-62a49cd2="">Jinbao Wang, Shuo Xu, Feng Zheng, Ke Lu,
                                    Jingkuan Song, Ling Shao</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Image Process. 2021</div><a
                                        class="lc-link"
                                        href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9474952"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport20.087301fa.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">20. Camera-Agnostic Person Re-Identification
                                    via Adversarial Disentangling Learning</div>
                                <div class="lc-info" data-v-62a49cd2="">Hao Ni, Jingkuan Song, Xiaosu Zhu, Feng Zheng,
                                    Lianli Gao</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">ACM Multimedia 2021</div><a
                                        class="lc-link" href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475361"
                                        data-v-62a49cd2="">PDF</a><a class="lc-link"
                                        href="https://github.com/luckyaci/ADL_ReID" data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport3.8a220c35.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">19. 3D Self-Attention for Unsupervised Video
                                    Quantization</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Ruimin Lang, Xiaosu Zhu, Xing Xu,
                                    Lianli Gao, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">SIGIR 2020</div><a class="lc-link"
                                        href="https://dl.acm.org/doi/pdf/10.1145/3397271.3401122"
                                        data-v-62a49cd2="">PDF</a><a class="lc-link"
                                        href="https://github.com/brownwolf/3D-UVQ" data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport10.a293f1c0.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">18. Binary neural networks: A survey</div>
                                <div class="lc-info" data-v-62a49cd2="">Haotong Qin, Ruihao Gong, Xianglong Liu, Xiao
                                    Bai, Jingkuan Song, Nicu Sebe</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">Pattern Recognit. 2020</div><a
                                        class="lc-link" href="https://arxiv.org/pdf/2004.03333.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport14.7b62d2ff.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">17. SNEQ: Semi-Supervised Attributed Network
                                    Embedding with Attention-Based Quantisation</div>
                                <div class="lc-info" data-v-62a49cd2="">Tao He, Lianli Gao, Jingkuan Song, Xin Wang,
                                    Kejie Huang, Yuanfang Li</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">AAAI 2020</div><a class="lc-link"
                                        href="https://ojs.aaai.org/index.php/AAAI/article/view/5832"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport18.44a63dca.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">16. Salience-Guided Cascaded Suppression
                                    Network for Person Re-Identification</div>
                                <div class="lc-info" data-v-62a49cd2="">Xuesong Chen, Canmiao Fu, Yong Zhao, Feng Zheng,
                                    Jingkuan Song, Rongrong Ji, Yi Yang</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">CVPR 2020</div><a class="lc-link"
                                        href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Salience-Guided_Cascaded_Suppression_Network_for_Person_Re-Identification_CVPR_2020_paper.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport19.14a002a3.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">15. Forward and Backward Information Retention
                                    for Accurate Binary Neural Networks</div>
                                <div class="lc-info" data-v-62a49cd2="">Haotong Qin, Ruihao Gong, Xianglong Liu, Mingzhu
                                    Shen, Ziran Wei, Fengwei Yu, Jingkuan Song</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">CVPR 2020</div><a class="lc-link"
                                        href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Qin_Forward_and_Backward_Information_Retention_for_Accurate_Binary_Neural_Networks_CVPR_2020_paper.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport6.bbd07bd3.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">14. One Network for Multi-Domains: Domain
                                    Adaptive Hashing with Intersectant Generative Adversarial Networks</div>
                                <div class="lc-info" data-v-62a49cd2="">Tao He, Yuan-Fang Li, Lianli Gao, Dongxiang
                                    Zhang, Jingkuan Song</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IJCAI 2019</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/1907.00612v1.pdf" data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport7.451d3093.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">13. Deep Recurrent Quantization for Generating
                                    Sequential Binary Codes</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Xiaosu Zhu, Lianli Gao, Xin-Shun
                                    Xu, Wu Liu, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IJCAI 2019</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/1906.06699v2.pdf" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href="https://github.com/cfm-uestc/DRQ"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport8.d3ac5e9e.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">12. Beyond Product Quantization: Deep
                                    Progressive Quantization for Image Retrieval</div>
                                <div class="lc-info" data-v-62a49cd2="">Lianli Gao, Xiaosu Zhu, Jingkuan Song, Zhou
                                    Zhao, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IJCAI 2019</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/1906.06698.pdf" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href="https://github.com/cfm-uestc/DPQ"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport15.660e6d17.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">11. 3D Self-Attention for Unsupervised Video
                                    Quantization</div>
                                <div class="lc-info" data-v-62a49cd2="">Zhu Zhang, Zhou Zhao, Zhijie Lin, Jingkuan Song,
                                    Deng Cai</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IJCAI 2019</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/1906.12165.pdf" data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport1.ebab9a34.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">10. Deep region hashing for generic instance
                                    search from images</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Tao He, Lianli Gao, Xing Xu, Heng
                                    Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">AAAI 2018</div><a class="lc-link"
                                        href="https://dl.acm.org/doi/pdf/10.5555/3504035.3504085"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport2.c23e0941.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">9. Binary Generative Adversarial Networks for
                                    Image Retrieval</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Tao He, Lianli Gao, Xing Xu, Alan
                                    Hanjalic, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">AAAI 2018</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/1708.04150v1.pdf" data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport4.28978424.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">8. Self-Supervised Video Hashing With
                                    Hierarchical Binary Auto-Encoder</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Hanwang Zhang, Xiangpeng Li,
                                    Lianli Gao, Meng Wang, Richang Hong</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Image Process. 2018</div><a
                                        class="lc-link" href="https://arxiv.org/pdf/1802.02305v1.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport5.e94889b5.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">7. Quantization-based hashing: a general
                                    framework for scalable image and video retrieval</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Lianli Gao, Li Liu, Xiaofeng Zhu,
                                    Nicu Sebe</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">Pattern Recognit. 2018</div><a
                                        class="lc-link"
                                        href="https://www.sciencedirect.com/science/article/pii/S0031320317301322"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport11.c9946f8d.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">6. A Survey on Learning to Hash</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingdong Wang, Ting Zhang, Jingkuan Song, Nicu
                                    Sebe, and Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Pattern Anal. Mach. Intell.
                                        2018</div><a class="lc-link" href="https://arxiv.org/pdf/1606.00185.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport13.8c8ddba6.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">5. Cross-Paced Representation Learning With
                                    Partial Curricula for Sketch-Based Image Retrieval</div>
                                <div class="lc-info" data-v-62a49cd2="">Dan Xu, Xavier Alameda-Pineda, Jingkuan Song,
                                    Elisa Ricci, Nicu Sebe:</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Image Process. 2018</div><a
                                        class="lc-link" href="https://arxiv.org/pdf/1803.01504.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport16.c48a7fe1.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">4. NAIS: Neural Attentive Item Similarity Model
                                    for Recommendation</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Ruimin Lang, Xiaosu Zhu, Xing Xu,
                                    Lianli Gao, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Knowl. Data Eng. 2018</div><a
                                        class="lc-link" href="https://arxiv.org/pdf/1809.07053.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport22.b098ae93.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">3. Complementary Binary Quantization for Joint
                                    Multiple Indexing</div>
                                <div class="lc-info" data-v-62a49cd2="">Qiang Fu, Xu Han, Xianglong Liu, Jingkuan Song,
                                    Cheng Deng</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IJCAI 2018</div><a class="lc-link"
                                        href="https://www.ijcai.org/proceedings/2018/0292.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport24.d6116c53.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">2. Towards Accurate Georeferenced Video Search
                                    With Camera Field of View Modeling</div>
                                <div class="lc-info" data-v-62a49cd2="">Jie Shao, Gang Hu, Jingkuan Song, Xueliang Liu,
                                    Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Circuits Syst. Video Technol.
                                        2018</div><a class="lc-link"
                                        href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Salience-Guided_Cascaded_Suppression_Network_for_Person_Re-Identification_CVPR_2020_paper.pdf"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/compactreport17.85785284.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">1. Deep Self-Taught Hashing for Image Retrieval</div>
                                <div class="lc-info" data-v-62a49cd2="">Yu Liu, Jingkuan Song, Ke Zhou, Lingyu Yan, Li
                                    Liu, Fuhao Zou, Ling Shao</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Cybern. 2015</div><a
                                        class="lc-link"
                                        href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8354809"
                                        data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

            </div>
        </div>
    </div>
    </div>
    <!-- built files will be auto injected -->


    <div>
        <div class="_th-container">
            <div class="_th-click-hover _item-input">
                x1.00
            </div>
            <div class="_th-item _item-x2">&gt;</div>
            <div class="_th-item _item-x-2">&lt;</div>
            <div class="_th-item _item-xx2">&gt;&gt;</div>
            <div class="_th-item _item-xx-2">&lt;&lt;</div>
            <div class="_th-item _item-reset">O</div>
        </div>
        <div class="_th_cover-all-show-times _th_hidden">
            <div class="_th_times">x1.00</div>
        </div>
    </div>
</body>

</html>