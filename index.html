<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <link rel="icon" href="favicon.ico">
    <title>Homepage of Jingkuan Song, UESTC</title>
    <script defer="" src="js/chunk-vendors.js"></script>
    <script defer="" src="js/app.js"></script>
    <style type="text/css">
        body {
            height: 100%;
            width: 100%;
            font-family: "OpenSans", Helvetica, Arial, sans-serif;
            font-weight: 400;
            font-size: 15px;
            color: #555;
            line-height: 22px;
        }
    </style>
    <style type="text/css">
        .sc-item[data-v-0ff541a6] {
            margin-bottom: 10px;
        }
    </style>
    <style type="text/css">
        .sl-container[data-v-5cd10541] {
            box-shadow: 0 6px 5px -7px gray;
            padding: 30px 1%;
            color: #555;
        }
    </style>
    <style type="text/css">
        .lc-container[data-v-62a49cd2] {
            box-shadow: 0 6px 5px -7px gray;
        }

        .lc-box[data-v-62a49cd2] {
            padding: 10px 0 20px 0;
            border-bottom: solid 1px #EEE;
            display: flex;
        }

        .lc-cover[data-v-62a49cd2] {
            width: 150px;
            height: auto;
            margin-right: 50px;
        }

        .lc-title[data-v-62a49cd2] {
            font-weight: bold;
        }

        .lc-info[data-v-62a49cd2] {
            margin: 10px 0 10px 0;
            font-style: italic;
        }

        .lc-publish[data-v-62a49cd2] {
            color: #500;
            margin-right: 20px;
        }

        .lc-link-box[data-v-62a49cd2] {
            display: flex;
        }

        .lc-link[data-v-62a49cd2] {
            color: #0088CC;
            margin: 0 2px 0 5px;
        }

        img[data-v-62a49cd2] {
            width: 100%;
            height: auto;
            border-radius: 5px;
        }

        h2[data-v-62a49cd2] {
            font-size: 30px;
            color: #970024;
        }
    </style>
    <style type="text/css">
        .l-link[data-v-702382f0] {
            color: #0088CC;
        }

        .sep[data-v-702382f0] {
            margin: 0 2px 0 0;
        }

        p[data-v-702382f0] {
            float: left;
            word-break: break-all;
            margin: 0 0 10px;
        }
    </style>
    <style type="text/css">
        .container[data-v-0c6f0290] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }

        .info-box[data-v-0c6f0290] {
            width: 100%;
            display: flex;
            box-shadow: 0 6px 5px -7px gray;
            padding: 10px 1%;
        }

        .avatar-box[data-v-0c6f0290] {
            width: 35%;
            height: auto;
            margin-top: 15px;
            padding: 0 1.5%;
        }

        .info[data-v-0c6f0290] {
            width: 60%;
            padding: 0 1.5%;
        }

        .pad[data-v-0c6f0290] {
            width: 5%;
        }

        .job-title[data-v-0c6f0290] {
            font-style: italic;
            margin: 0 0 10px;
        }

        img[data-v-0c6f0290] {
            width: 100%;
            height: auto;
            border-radius: 5px;
        }

        h1[data-v-0c6f0290] {
            font-size: 36px;
            color: darkblue;
            margin: 0 0 10px;
        }
    </style>
    <style type="text/css">
        li[data-v-1eaa13bc] {
            padding-left: 20px;
        }
    </style>
    <style type="text/css">
        h1[data-v-3a4951d4] {
            font-size: 30px;
            color: darkblue;
            padding-bottom: 10px;
            border-bottom: solid 1px #EEE;
        }
    </style>
    <style type="text/css">
        .container[data-v-0a2d6c68] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        .container[data-v-dcb24c48] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        .container[data-v-247c96ae] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        .container[data-v-606756d4] {
            margin: 40px auto;
            max-width: 1000px;
            font-size: 1em;
        }
    </style>
    <style type="text/css">
        ._th-container ._th-item {
            margin-bottom: 3px;
            position: relative;
            width: 0;
            height: 0;
            cursor: pointer;
            opacity: .3;
            background-color: aquamarine;
            border-radius: 100%;
            text-align: center;
            line-height: 30px;
            -webkit-transition: all .35s;
            -o-transition: all .35s;
            transition: all .35s;
            right: 30px
        }

        ._th-container ._th-item,
        ._th-container ._th-click-hover,
        ._th_cover-all-show-times ._th_times {
            -webkit-box-shadow: -3px 4px 12px -5px black;
            box-shadow: -3px 4px 12px -5px black
        }

        ._th-container:hover ._th-item._item-x2 {
            margin-left: 18px;
            width: 40px;
            height: 40px;
            line-height: 40px
        }

        ._th-container:hover ._th-item._item-x-2 {
            margin-left: 17px;
            width: 38px;
            height: 38px;
            line-height: 38px
        }

        ._th-container:hover ._th-item._item-xx2 {
            width: 36px;
            height: 36px;
            margin-left: 16px;
            line-height: 36px
        }

        ._th-container:hover ._th-item._item-xx-2 {
            width: 32px;
            height: 32px;
            line-height: 32px;
            margin-left: 14px
        }

        ._th-container:hover ._th-item._item-reset {
            width: 30px;
            line-height: 30px;
            height: 30px;
            margin-left: 10px
        }

        ._th-click-hover {
            position: relative;
            -webkit-transition: all .5s;
            -o-transition: all .5s;
            transition: all .5s;
            height: 45px;
            width: 45px;
            cursor: pointer;
            opacity: .3;
            border-radius: 100%;
            background-color: aquamarine;
            text-align: center;
            line-height: 45px;
            right: 0
        }

        ._th-container:hover {
            left: -5px
        }

        ._th-container {
            font-size: 12px;
            -webkit-transition: all .5s;
            -o-transition: all .5s;
            transition: all .5s;
            left: -35px;
            top: 20%;
            position: fixed;
            -webkit-box-sizing: border-box;
            box-sizing: border-box;
            z-index: 100000;
            -webkit-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            user-select: none
        }

        ._th-container ._th-item:hover {
            opacity: .8;
            background-color: #5fb492;
            color: aliceblue
        }

        ._th-container ._th-item:active {
            opacity: .9;
            background-color: #1b3a26;
            color: aliceblue
        }

        ._th-container:hover ._th-click-hover {
            opacity: .8
        }

        ._th-container:hover ._th-item {
            opacity: .6;
            right: 0
        }

        ._th-container ._th-click-hover:hover {
            opacity: .8;
            background-color: #5fb492;
            color: aliceblue
        }

        ._th_cover-all-show-times {
            position: fixed;
            top: 0;
            right: 0;
            width: 100%;
            height: 100%;
            z-index: 99999;
            opacity: 1;
            font-weight: 900;
            font-size: 30px;
            color: #4f4f4f;
            background-color: rgba(0, 0, 0, 0.1)
        }

        ._th_cover-all-show-times._th_hidden {
            z-index: -99999;
            opacity: 0;
            -webkit-transition: 1s all;
            -o-transition: 1s all;
            transition: 1s all
        }

        ._th_cover-all-show-times ._th_times {
            width: 300px;
            height: 300px;
            border-radius: 50%;
            background-color: rgba(127, 255, 212, 0.51);
            text-align: center;
            line-height: 300px;
            position: absolute;
            top: 50%;
            right: 50%;
            margin-top: -150px;
            margin-right: -150px
        }
    </style>
</head>

<body>
    <noscript>
        <strong>We're sorry but songjingkuan doesn't work properly without JavaScript enabled. Please enable it to
            continue.</strong>
    </noscript>
    <div id="app" data-v-app="">
        <div id="container">
            <div class="container" data-v-0c6f0290="">

                <div class="info-box" data-v-0c6f0290="">
                    <div class="avatar-box" data-v-0c6f0290=""><img src="img/IMG_1546.jpg" data-v-0c6f0290="">
                    </div>
                    <div class="info" data-v-0c6f0290="">
                        <h1 data-v-0c6f0290="">Jingkuan Song</h1>
                        <div class="job-title" data-v-0c6f0290="">Professor</div>
                        <div class="sc-container" data-v-0ff541a6="" data-v-0c6f0290="">
                            <div data-v-0ff541a6="">
                                <div class="sc-item" data-v-0ff541a6="">
                                    <a href="https://www.scse.uestc.edu.cn/" class="l-link" data-v-702382f0="">School of
                                        Computer Science and Engineering, UESTC</a>
                                    <br>Email: jingkuan.song@gmail.com
                                    <br>Office: No.A304 Innovation Center
                                </div>
                            </div>
                            <div data-v-0ff541a6="">
                                <div class="sc-item" data-v-0ff541a6="" style="text-align:justify">Jingkuan Song is a
                                    full professor with
                                    University of Electronic Science and Technology of China (UESTC). He joined Columbia
                                    University as a Postdoc Research Scientist (2016-2017), and University of
                                    Trento as a Research Fellow (2014-2016) (advised by Prof. <a
                                        href="http://disi.unitn.it/~sebe/" class="l-link" data-v-702382f0="">Nicu
                                        Sebe)</a>. He obtained his PhD degree from The University of Queensland (UQ),
                                    Australia (advised by Prof. <a href="http://cfm.uestc.edu.cn/~shenht/"
                                        class="l-link" data-v-702382f0="">Heng Tao Shen)</a>. His research interests
                                    mainly focus on Multimedia Compact Repersentation and Analysis. He was the winner of
                                    the Best Paper Award in ICPR (2016,
                                    Mexico), Best Student Paper Award in Australian Database Conference (2017,
                                    Australia), Best Paper Honorable Mention Award in SIGIR (2017, Japan), Best Paper
                                    Runner-up Award in ApWEB (2019, China) and ACM SIGMM Rising Star Award 2021. He is
                                    Associate Editor of <a
                                        href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046"
                                        class="l-link" data-v-702382f0="">IEEE TMM</a>, <a
                                        href="https://dl.acm.org/journal/tomm" class="l-link" data-v-702382f0="">ACM
                                        TOMM</a>, Guest Editor of TMM, PR and AC/SPC/PC member of CVPR’18-'23, ACM
                                    MM'18-'23, IJCAI'18-'23, etc.</div>
                            </div>
                            <div data-v-0ff541a6="">
                                <div class="sc-item" data-v-0ff541a6="" style="text-align:justify"><b>I am looking for
                                        highly motivated PhD
                                        students, Postdoctorals and Assistant Professors to conduct world-class research
                                        in my team. Please send your CV or enquiries to my email.</b></div>
                            </div>
                        </div>


                        <p data-v-702382f0=""><span class="l-box" data-v-702382f0=""><a href="our-group.html"
                                    class="l-link" data-v-702382f0="">Our Group</a><span class="sep" data-v-702382f0="">
                                    | </span></span>
                            <span class="l-box" data-v-702382f0=""><a
                                    href="https://scholar.google.com/citations?hl=en&amp;user=F5Zy9V4AAAAJ"
                                    class="l-link" data-v-702382f0="">Google Scholar</a><span class="sep"
                                    data-v-702382f0=""> | </span></span>
                            <span class="l-box" data-v-702382f0=""><a href="https://dblp.uni-trier.de/pid/70/10575.html"
                                    class="l-link" data-v-702382f0="">DBLP</a><span class="sep" data-v-702382f0="">
                                    | </span></span>
                            <span class="l-box" data-v-702382f0=""><a href="#service" class="l-link"
                                    data-v-702382f0="">Service</a><span class="sep" data-v-702382f0="">
                                    | </span></span>
                            <span class="l-box" data-v-702382f0=""><a href="#awards" class="l-link"
                                    data-v-702382f0="">Awards</a><span class="sep" data-v-702382f0="">
                                    | </span></span>
                            <span class="l-box" data-v-702382f0=""><a
                                    href="https://vl-group.github.io/seminars/all_seminars.html" class="l-link"
                                    data-v-702382f0="">Group Seminars</a></span>
                            <br>
                            <span class="l-box" data-v-702382f0=""><a href="compact-representation.html" class="l-link"
                                    data-v-702382f0="">Compact
                                    Representation</a><span class="sep" data-v-702382f0=""> | </span></span><span
                                class="l-box" data-v-702382f0=""><a href="cross-media-analysis.html" class="l-link"
                                    data-v-702382f0="">Cross-media Analysis</a><span class="sep" data-v-702382f0=""> |
                                </span></span><span class="l-box" data-v-702382f0=""><a href="ai-safety.html"
                                    class="l-link" data-v-702382f0="">Representation Safety</a></span>
                        </p>
                        <div data-v-702382f0="" style="clear: both;"></div>
                    </div>
                    <div class="pad" data-v-0c6f0290=""></div>
                </div>

                <div class="sl-container" data-v-5cd10541="" data-v-0c6f0290="">
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><span style="color: red; font-weight: bold;">NEW</span> Jan. 2023: We won
                            the fist prize of <a href="https://mp.weixin.qq.com/s/svHNymkk6bFjT4F8KJrzLw" class="l-link"
                                data-v-702382f0="">'Ingenuity Cup' National Artificial Intelligence
                                Innovation(兴智杯全国人工智能创新大赛)!</a></li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><span style="color: red; font-weight: bold;">NEW</span>
                            Oct. 2022: We are organizing <a href="https://hcma2022.github.io/" class="l-link"
                                data-v-702382f0="">HCMA'22: 3rd International Workshop on Human-Centric Multimedia
                                Analysis</a> in ACM Multimedia 2022!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Sep. 2022: 3 NeurIPS papers are accepted!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Aug. 2022: 8 ACM Multimedia papers are accepted!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Jun. 2022: 1 TPAMI paper is accepted!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Mar. 2022: 5 CVPR papers &amp; 2 ECCV papers are accepted!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Jan 2022: I serve as Associate Editor for IEEE TMM!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Oct. 2021: I am luckily to be the winner of <a
                                href="http://www.sigmm.org/news/sigmm_rising_star_award_2021" class="l-link"
                                data-v-702382f0="">the SIGMM Rising Star 2021</a> for my contributions in Multimedia
                            Compact Representation and Analysis.
                        </li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">July 2021: We won the first place of CVPR2021 AI Security Challenge
                            (1/1568)!</li>
                    </div>

                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">May 2021: I will
                            serve as Technical Demo Chairs for ACM MM 21!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">May 2021: 2 IJCAI &amp; 1 AAAI are accepted!</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Aug 2020: 4 ACM MM &amp; 2 IJCAI &amp; 1 ECCV &amp; 1 AAAI are accepted!
                        </li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">Jan 2020: I serve as Associate Editor for ACM TOMM!</li>
                    </div>

                </div>
                <div class="lc-container" data-v-62a49cd2="" data-v-0c6f0290="">
                    <h2 data-v-62a49cd2="">Highlighted Papers</h2>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight1.b249c2a8.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">9. A Lower Bound of Hash Codes' Performance
                                </div>
                                <div class="lc-info" data-v-62a49cd2="">Xiaosu Zhu, Jingkuan Song, Yu Lei, Lianli Gao,
                                    Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">NeurIPS 2022</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/2210.05899.pdf" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href=" https://github.com/VL-Group/LBHash"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight3.ca2744ae.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">8. Label-Guided Generative Adversarial Network
                                    for Realistic Image Synthesis</div>
                                <div class="lc-info" data-v-62a49cd2="">Junchen Zhu, Lianli Gao, Jingkuan Song,
                                    Yuan-Fang Li, Feng Zheng, Xuelong Li, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">TPAMI, 2022</div><a class="lc-link"
                                        href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9810175"
                                        data-v-62a49cd2="">PDF</a><a class="lc-link"
                                        href="https://github.com/RoseRollZhu/Lab2Pix-V2" data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight5.a24b97fb.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">7. Natural Color Fool: Towards Boosting
                                    Black-box Unrestricted Attacks</div>
                                <div class="lc-info" data-v-62a49cd2="">Shengming Yuan, Qilong Zhang, Lianli Gao, Yaya
                                    Cheng, Jingkuan Song</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">NeurIPS 2022</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/2210.02041v1.pdf" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href="https://github.com/ylhz/Natural-Color-Fool"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight6.cbe1e454.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">6. Beyond ImageNet Attack: Towards Crafting
                                    Adversarial Examples for Black-box Domains</div>
                                <div class="lc-info" data-v-62a49cd2="">Qilong Zhang, Xiaodan Li, Yuefeng Chen, Jingkuan
                                    Song, Lianli Gao, Yuan He, Hui Xue</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">ICLR&nbsp;2022</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/2201.11528v4.pdf" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href="https://github.com/Alibaba-AAIG/Beyond-ImageNet-Attack"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight7.cfc3a36d.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">5. Unified Multivariate Gaussian Mixture for
                                    Efficient Neural Image Compression</div>
                                <div class="lc-info" data-v-62a49cd2="">Xiaosu Zhu, Jingkuan Song, Lianli Gao, Feng
                                    Zheng, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">CVPR&nbsp;2022</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/2203.10897.pdf" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href="https://github.com/xiaosu-zhu/McQuic"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight8.17fda1b8.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">4. A Differentiable Semantic Metric
                                    Approximation in Probabilistic Embedding for Cross-Modal Retrieval</div>
                                <div class="lc-info" data-v-62a49cd2="">Hao Li, Jingkuan Song, Lianli Gao, Pengpeng
                                    Zeng, Haonan Zhang, Gongfu Li</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">NeurIPS 2022</div><a class="lc-link"
                                        href="https://openreview.net/pdf?id=-KPNRZ8i0ag" data-v-62a49cd2="">PDF</a><a
                                        class="lc-link" href="https://github.com/leolee99/2022-NeurIPS-DAA"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight2.68597392.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">3. Unified Binary Generative Adversarial
                                    Network for Image Retrieval and Compression</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Tao He, Lianli Gao, Xing Xu, Alan
                                    Hanjalic, Heng Tao Shen:</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IJCV 2020</div><a class="lc-link"
                                        href="https://link.springer.com/content/pdf/10.1007/s11263-020-01305-2.pdf?pdf=button"
                                        data-v-62a49cd2="">PDF</a><a class="lc-link"
                                        href="https://github.com/RoseRollZhu/Lab2Pix-V2" data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight4.996bfe6a.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">2. Hierarchical LSTMs with Adaptive Attention
                                    for Visual Captioning</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingkuan Song, Xiangpeng Li, Lianli Gao, Heng
                                    Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">IEEE Trans. Pattern Anal. Mach. InAtell.
                                        2020</div><a class="lc-link" href="https://arxiv.org/pdf/1812.11004v1.pdf"
                                        data-v-62a49cd2="">PDF</a><a class="lc-link"
                                        href="https://github.com/lixiangpengcs/Spatial-Temporal-Adaptive-Attention-for-Video-Captioning"
                                        data-v-62a49cd2="">CODE</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div data-v-62a49cd2="">
                        <div class="lc-box" data-v-62a49cd2="">
                            <div class="lc-cover" data-v-62a49cd2=""><img src="img/highlight9.99b6fefc.png"
                                    data-v-62a49cd2=""></div>
                            <div data-v-62a49cd2="">
                                <div class="lc-title" data-v-62a49cd2="">1. A Survey on Learning to Hash</div>
                                <div class="lc-info" data-v-62a49cd2="">Jingdong Wang, Ting Zhang, Jingkuan Song, Nicu
                                    Sebe, Heng Tao Shen</div>
                                <div class="lc-link-box" data-v-62a49cd2="">
                                    <div class="lc-publish" data-v-62a49cd2="">TPAMI 2018</div><a class="lc-link"
                                        href="https://arxiv.org/pdf/1606.00185.pdf" data-v-62a49cd2="">PDF</a>
                                    <!--v-if-->
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Services -->
                <div class="sl-container" data-v-5cd10541="" data-v-0c6f0290="" id="service">
                    <h2 data-v-62a49cd2="">Service</h2>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Associate Editor</b>: IEEE Transactions on Multimedia</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Associate Editor</b>: ACM Transactions on Multimedia Computing
                            Communications and Applications</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Lead Guest Editor</b>: IEEE Transaction on Multimedia, special issue
                            on `Large-scale Multimedia Data Retrieval, Classification, and Understanding'.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Lead Guest Editor</b>: World Wide Web Journal, `Deep vs Shallow:
                            Learning for Emerging Web-scale Data Computing and Applications'.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Area Chair</b>: ACM Multimedia 2018-2023, ICPR 2019-2022, WACV
                            2021-2023, etc.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Workshop/Demo/GC Chair</b>: APWeb 2019, ACM Multimedia 2021, MMAsia
                            2020-2021, etc.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Senior PC Member</b>: AAAI 2020-2022, IJCAI 2021, etc.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>PC Member</b>: ACM Multimedia‘17-'22, ECCV'16-'22, CVPR'17-'22,
                            ICCV'17-'22, etc.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541=""><b>Reviewer</b>: IEEE Transactions on Image Processing, IEEE Transactions
                            on Pattern Analysis and Machine Intelligence, IEEE Transactions on Knowledge and Data
                            Engineering, IEEE Transactions on Cybernetics, IEEE Transactions on Multimedia, IEEE
                            Transactions on Circuits and Systems for Video Technology, etc.</li>
                    </div>
                </div>


                <!-- Awards -->
                <div class="sl-container" data-v-5cd10541="" data-v-0c6f0290="" id="awards">
                    <h2 data-v-62a49cd2="">Hornors and Awards</h2>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2022 The Fist prize of `Ingenuity Cup' National Artificial Intelligence
                            Innovation Application Competition.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2021 ACM SIGMM Rising Star Award</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2021 The Second prize of `China College Computing Contest-Artificial
                            Intelligence Innovation Contest'.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2021 the First place of CVPR2021 AI Security Challenge (1/1568).</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2020 Aminer AI 2000: most Influential Scholar Award (Honorable Mention).
                        </li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2019 ACM China SIGMM Rising Star.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2019 Best Paper Runner-up Award, for APWeb 2019.</li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2017 Best Student Paper Award, for Australasian Database Conference 2017
                        </li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2016 Best Paper Honorable Mention Award, for ACM SIGIR conference 2017.
                        </li>
                    </div>
                    <div data-v-5cd10541="">
                        <li data-v-5cd10541="">2016 Best Scientific Paper Award, for International Conference on Pattern
                            Recognition 2016.</li>
                    </div>
                </div>


            </div>
        </div>
    </div>
    <!-- built files will be auto injected -->








    <div>
        <div class="_th-container">
            <div class="_th-click-hover _item-input">
                x1.00
            </div>
            <div class="_th-item _item-x2">&gt;</div>
            <div class="_th-item _item-x-2">&lt;</div>
            <div class="_th-item _item-xx2">&gt;&gt;</div>
            <div class="_th-item _item-xx-2">&lt;&lt;</div>
            <div class="_th-item _item-reset">O</div>
        </div>
        <div class="_th_cover-all-show-times _th_hidden">
            <div class="_th_times">x1.00</div>
        </div>
    </div>
</body>

</html>